{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NXP DL CNN Explained.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hwankang/Defense/blob/main/NXP_DL_CNN_Explained.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhZOHbwJOvio"
      },
      "source": [
        "## 이미지 분류를 위한 CNN의 이해 / What are Convolutions?\n",
        "\n",
        "* In the next lab you will explore how to enhance your Computer Vision example using Convolutions. \n",
        "* But what are convolutions? In this lab you'll explore what they are and how they work, \n",
        "* and then in Lab 4 you'll see how to use them in your neural network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nidI4HtcVQ7i"
      },
      "source": [
        "### 이미지 압축 및 강화 기법: Pooling\n",
        "\n",
        "* Together with convolutions, you'll use something called 'Pooling', \n",
        "* which compresses your image, further emphasising the features. \n",
        "* You'll also see how pooling works in this lab. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdBFQswdO-kX"
      },
      "source": [
        "## 이미지 분류에 있어 DNN의 한계 / Limitations of the previous DNN\n",
        "\n",
        "* In the last lab you saw how to train an image classifier for fashion items using the Fashion MNIST dataset. \n",
        "* This gave you a pretty accuract classifier, \n",
        "* but there was an obvious constraint: the images were 28x28, grey scale and the item was centered in the image. \n",
        "\n",
        "For example here are a couple of the images in Fashion MNIST\n",
        "![Picture of a sweater and a boot](https://cdn-images-1.medium.com/max/1600/1*FekMt6abfFFAFzhQcnjxZg.png)\n",
        "\n",
        "### DNN의 한계: 상황 속의 아이템 인식 문제\n",
        "\n",
        "The DNN that you created simply learned from the raw pixels what made up a sweater, and what made up a boot in this context. But consider how it might classify this image?\n",
        "\n",
        "![image of boots](https://cdn.pixabay.com/photo/2013/09/12/19/57/boots-181744_1280.jpg)\n",
        "\n",
        "### DNN의 한계: 작은 크기, 명확한 이미지만 효과적으로 분류 \n",
        "\n",
        "While it's clear that there are boots in this image, the classifier would fail for a number of reasons. First, of course, it's not 28x28 greyscale, but more importantly, the classifier was trained on the raw pixels of a left-facing boot, and not the features that make up what a boot is.\n",
        "\n",
        "### CNN의 해법: 이미지 분류 전 이미지 필터링 시행\n",
        "\n",
        "That's where Convolutions are very powerful. A convolution is a filter that passes over an image, processing it, and extracting features that show a commonolatity in the image. In this lab you'll see how they work, but processing an image to see if you can extract features from it!\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ds0NF5KFVmG2"
      },
      "source": [
        "### 콘볼루션 필터 생성하기\n",
        "\n",
        "* Generating convolutions is very simple\n",
        "* you simply scan every pixel in the image \n",
        "* and then look at it's neighboring pixels. \n",
        "* You multiply out the values of these pixels by the equivalent weights in a filter. \n",
        "\n",
        "So, for example, consider this:\n",
        "\n",
        "![Convolution on image](https://storage.googleapis.com/laurencemoroney-blog.appspot.com/MLColabImages/lab3-fig1.png)\n",
        "\n",
        "### 3x3 콘볼루션 필터 정의\n",
        "In this case a 3x3 Convolution is specified.\n",
        "\n",
        "The current pixel value is 192, but you can calculate the new one by looking at the neighbor values, and multiplying them out by the values specified in the filter, and making the new pixel value the final amount.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJTHvE8Qe5nM"
      },
      "source": [
        "## 2D 흑백 사진을 이용한 콘볼루션 필터의 이해\n",
        "\n",
        "* Let's explore how convolutions work by creating a basic convolution on a 2D Grey Scale image. \n",
        "* First we can load the image by taking the 'ascent' image from scipy. It's a nice, built-in picture with lots of angles and lines. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTS2sc5nQSCJ"
      },
      "source": [
        "### 라이브러리 임포트\n",
        "\n",
        "Let's start by importing some python libraries.\n",
        "\n",
        "* scipy.misc.ascent\n",
        "\n",
        "https://docs.scipy.org/doc/scipy/reference/generated/scipy.misc.ascent.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZ5OXYiolCUi"
      },
      "source": [
        "# misc.ascent()\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from scipy import misc\n",
        "i = misc.ascent()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRIzxjWWfJjk"
      },
      "source": [
        "### 사진 출력\n",
        "\n",
        "Next, we can use the pyplot library to draw the image so we know what it looks like."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4p0cfWcfIvi"
      },
      "source": [
        "# imshow()로 이미지 데이터 출력\n",
        "# show()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.grid(False)\n",
        "plt.gray()\n",
        "plt.axis(True)\n",
        "plt.imshow(i)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1mhZ_ZTfPWH"
      },
      "source": [
        "### 사진 관찰: 상황 데이터와 분리하기 어려운 계단 전경\n",
        "\n",
        "We can see that this is an image of a stairwell. There are lots of features in here that we can play with seeing if we can isolate them -- for example there are strong vertical lines.\n",
        "\n",
        "The image is stored as a numpy array, so we can create the transformed image by just copying that array. \n",
        "\n",
        "### 사진을 넘파이 배열로 저장, 사본 복제\n",
        "\n",
        "Let's also get the dimensions of the image so we can loop over it later. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5pxGq1SmJMD"
      },
      "source": [
        "# 이미지 데이터 복제\n",
        "# .shape[]\n",
        "# size_x에 이미지의 행 데이터 할당\n",
        "# size_y에 이미지의 열 데이터 할당\n",
        "\n",
        "i_transformed = np.copy(i)\n",
        "size_x = i_transformed.###[0]\n",
        "size_y = i_transformed.shape[#]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7PwNkiXfddd"
      },
      "source": [
        "### 다양한 3x3 콘볼루션 필터 적용 연습\n",
        "\n",
        "Now we can create a filter as a 3x3 array. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sN3imZannN5J"
      },
      "source": [
        "# 세 가지 필터 적용\n",
        "\n",
        "# This filter detects edges nicely\n",
        "# It creates a convolution that only passes through sharp edges and straight\n",
        "# lines.\n",
        "\n",
        "#Experiment with different values for fun effects.\n",
        "#filter = [ [0, 1, 0], [1, -4, 1], [0, 1, 0]]\n",
        "\n",
        "# A couple more filters to try for fun!\n",
        "#filter = [ [-1, -2, -1], [0, 0, 0], [1, 2, 1]]\n",
        "filter = [ [-1, 0, 1], [-2, 0, 2], [-1, 0, 1]]\n",
        "\n",
        "# If all the digits in the filter don't add up to 0 or 1, you \n",
        "# should probably do a weight to get it to do so\n",
        "# so, for example, if your weights are 1,1,1 1,2,1 1,1,1\n",
        "# They add up to 10, so you would set a weight of .1 if you want to normalize them\n",
        "weight  = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQmm_iBufmCz"
      },
      "source": [
        "### 콘볼루션 필터 네트워크를 생성하여 이미지에 반복 적용 \n",
        "\n",
        "Now let's create a convolution. We will iterate over the image, leaving a 1 pixel margin, and multiply out each of the neighbors of the current pixel by the value defined in the filter. \n",
        "\n",
        "i.e. the current pixel's neighbor above it and to the left will be multiplied by the top left item in the filter etc. etc. We'll then multiply the result by the weight, and then ensure the result is in the range 0-255\n",
        "\n",
        "Finally we'll load the new value into the transformed image. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "299uU2jAr90h"
      },
      "source": [
        "# 데이터 입력 범위: 1부터 size_x-1까지\n",
        "# 데이터 입력 범위: 1부터 size_y-1까지\n",
        "# 누적된 필터링 데이터에 가중치 곱\n",
        "\n",
        "for x in range(1, size_x-1):\n",
        "  for y in ###(1, size_y-1):\n",
        "      convolution = 0.0\n",
        "      convolution = convolution + (i[x - 1, y-1] * filter[0][0])\n",
        "      convolution = convolution + (i[x, y-1] * filter[0][1])\n",
        "      convolution = convolution + (i[x + 1, y-1] * filter[0][2])\n",
        "      convolution = convolution + (i[x-1, y] * filter[1][0])\n",
        "      convolution = convolution + (i[x, y] * filter[1][1])\n",
        "      convolution = convolution + (i[x+1, y] * filter[1][2])\n",
        "      convolution = convolution + (i[x-1, y+1] * filter[2][0])\n",
        "      convolution = convolution + (i[x, y+1] * filter[2][1])\n",
        "      convolution = convolution + (i[x+1, y+1] * filter[2][2])\n",
        "      convolution = convolution * weight\n",
        "      if(convolution<0):\n",
        "        convolution=0\n",
        "      if(convolution>255):\n",
        "        convolution=255\n",
        "      i_transformed[x, y] = convolution"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XA--vgvgDEQ"
      },
      "source": [
        "### 최종 변환된 이미지 확인\n",
        "\n",
        "Now we can plot the image to see the effect of the convolution!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oPhUPNhuGWC"
      },
      "source": [
        "# Plot the image. Note the size of the axes -- they are 512 by 512\n",
        "# i_transformed 이미지 출력\n",
        "\n",
        "plt.gray()\n",
        "plt.grid(False)\n",
        "plt.imshow(i_transformed)\n",
        "#plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Df7kw1m6XDwz"
      },
      "source": [
        "### 필터 배열의 값 변화에 따라 수직과 수평에 대한 강화 수준이 달라짐\n",
        "\n",
        "So, consider the following filter values, and their impact on the image.\n",
        "\n",
        "\n",
        "#### 수직선 강화\n",
        "Using -1,0,1,-2,0,2,-1,0,1 gives us a very strong set of vertical lines:\n",
        "\n",
        "![Detecting vertical lines filter](https://storage.googleapis.com/laurencemoroney-blog.appspot.com/MLColabImages/lab3-fig2.png)\n",
        "\n",
        "\n",
        "#### 수평선 강화\n",
        "Using -1, -2, -1, 0, 0, 0, 1, 2, 1 gives us horizontal lines:\n",
        "\n",
        "![Detecting horizontal lines](https://storage.googleapis.com/laurencemoroney-blog.appspot.com/MLColabImages/lab3-fig3.png)\n",
        "\n",
        "Explore different values for yourself! "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xF0FPplsgHNh"
      },
      "source": [
        "## 이미지 압축과 강화를 위한 풀링 / Pooling\n",
        "\n",
        "As well as using convolutions, pooling helps us greatly in detecting features. The goal is to reduce the overall amount of information in an image, while maintaining the features that are detected as present. \n",
        "\n",
        "There are a number of different types of pooling, but for this lab we'll use one called MAX pooling. \n",
        "\n",
        "### 이미지 영역 분할 >> 영역별 최고치 선택 >> 이들 값으로 압축된 픽셀 구성 \n",
        "The idea here is to iterate over the image, and look at the pixel and it's immediate neighbors to the right, beneath, and right-beneath. Take the largest (hence the name MAX pooling) of them and load it into the new image. Thus the new image will be 1/4 the size of the old -- with the dimensions on X and Y being halved by this process. You'll see that the features get maintained despite this compression!\n",
        "\n",
        "![Max Pooling](https://storage.googleapis.com/laurencemoroney-blog.appspot.com/MLColabImages/lab3-fig4.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWi0SuZ-U662"
      },
      "source": [
        "### 2x2 풀링\n",
        "* This code will show a (2, 2) pooling. \n",
        "* Run it to see the output, and you'll see that \n",
        "* while the image is 1/4 the size of the original, \n",
        "* the extracted features are maintained!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDHjf-ehaBqm"
      },
      "source": [
        "#zeros()\n",
        "new_x = int(size_x/2)\n",
        "new_y = int(size_y/2)\n",
        "newImage = np.###((new_x, new_y))\n",
        "\n",
        "# 0부터 size_x까지, 2씩 건너뜀\n",
        "# 0부터 size_y까지, 2씩 건너뜀\n",
        "for x in range(0, size_x, 2):\n",
        "  for y in range(0, size_y, 2):\n",
        "    pixels = []\n",
        "    pixels.append(i_transformed[x, y])\n",
        "    pixels.append(i_transformed[x+1, y])\n",
        "    pixels.append(i_transformed[x, y+1])\n",
        "    pixels.append(i_transformed[x+1, y+1])\n",
        "    pixels.sort(reverse=True)\n",
        "    newImage[int(x/2),int(y/2)] = pixels[0]\n",
        "\n",
        "# Plot the image. Note the size of the axes -- now 256 pixels instead of 512\n",
        "# newImage 이미지 출력\n",
        "plt.gray()\n",
        "plt.grid(False)\n",
        "plt.imshow(newImage)\n",
        "#plt.axis('off')\n",
        "plt.show()     \n",
        "    \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZWdU6dVYQm-"
      },
      "source": [
        "In the next lab you'll see how to add convolutions to your Fashion MNIST neural network to make it more efficient -- because it will classify based on features, and not on raw pixels. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-cJKtUhXEB9"
      },
      "source": [
        "### 미션: 아래 영역에 여러분이 원하는 이미지를 가져와서 콘볼루션 필터를 적용해 보세요!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORou_a4sXSOG"
      },
      "source": [
        "#### 1. 이미지 로딩"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "583P3tNXXjH2"
      },
      "source": [
        "#### 2. 콘볼루션 필터 적용"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kV2rZbSqXqvF"
      },
      "source": [
        "#### 3. 결과 이미지 확인"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7sSIdKKXv5P"
      },
      "source": [
        "#### 4. 이미지 풀링"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aa4LRscmX1yv"
      },
      "source": [
        "#### 5. 결과 이미지 확인"
      ]
    }
  ]
}