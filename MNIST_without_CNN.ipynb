{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST without CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hwankang/Defense/blob/main/MNIST_without_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wF5wszaj97Y"
      },
      "source": [
        "# DL 손글씨 이미지 분류 기법의 이해\n",
        "\n",
        "* Author: Tensorflow\n",
        "* Lecture: Jason Dong"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ninYXwEDdtls"
      },
      "source": [
        "### 미션: MNIST 손글씨 예제 설명하기\n",
        "\n",
        "* MNIST 손글씨 데이터 시각화 및 데이터 탐색\n",
        "* 분석 정확도 개선 수준 측정"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04QgGZc9bF5D"
      },
      "source": [
        "### 케라스 활용 방법 소개\n",
        "#### This short introduction uses [Keras](https://www.tensorflow.org/guide/keras/overview) to:\n",
        "\n",
        "1. 신경망모델 이용, 이미지 분류 / Build a neural network that classifies images.\n",
        "2. 신경망모델 훈련시키기 / Train this neural network.\n",
        "3. 신경망모델의 성능 평가 / Evaluate the accuracy of the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnrWf3PCEzXL"
      },
      "source": [
        "### 1. 텐서플로2 임포트 \n",
        "#### Import TensorFlow into your program:\n",
        "\n",
        "* Note: Upgrade `pip` to install the TensorFlow 2 package. \n",
        "* See the [install guide](https://www.tensorflow.org/install) for details."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3-fippdp_Ac"
      },
      "source": [
        "# 라이브러리 임포트\n",
        "import ### as np # linear algebra\n",
        "import ### as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Plot ad hoc mnist instances from Keras datasets\n",
        "from keras.### import mnist\n",
        "import matplotlib.### as plt\n",
        "\n",
        "print(np.__version__)\n",
        "print(pd.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0trJmd6DjqBZ"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66znm5uxfLii"
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NAbSZiaoJ4z"
      },
      "source": [
        "### 2. MNIST 데이터세트 로딩\n",
        "#### 정수형 데이터를 실수형 데이터로 변환\n",
        "\n",
        "* Load and prepare the [MNIST dataset](http://yann.lecun.com/exdb/mnist/). \n",
        "* Convert the samples from integers to floating-point numbers:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FP5258xjs-v"
      },
      "source": [
        "# .datasets\n",
        "mnist = tf.keras.###.mnist\n",
        "\n",
        "# 훈련용: (피처, 타겟)\n",
        "# 검증용: (피처, 타겟)\n",
        "# load_data()\n",
        "(x_train, y_train), (x_test, y_test) = mnist.###()\n",
        " \n",
        "# 24x24 픽셀 이미지의 픽셀의 흑백 수준을 정규화\n",
        "# 원본: 백 0~255 흑\n",
        "# 정규화: 흑 0 ~ 1 백\n",
        "x_train, x_test = x_train / ###, x_test / ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDIATkMzhTSy"
      },
      "source": [
        "x_train[:1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4dVNgd1qV89"
      },
      "source": [
        "# 이미지 데이터 시각화 및 탐색\n",
        "# plot 4 images as gray scale\n",
        "# subplot()\n",
        "# imshow()\n",
        "\n",
        "plt.###(221)\n",
        "plt.imshow(x_train[100], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(222)\n",
        "plt.imshow(x_train[1], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(223)\n",
        "plt.imshow(x_train[2], cmap=plt.get_cmap('gray'))\n",
        "plt.subplot(224)\n",
        "plt.###(x_train[3], cmap=plt.get_cmap('gray'))\n",
        "\n",
        "# show the plot\n",
        "plt.###()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPZ68wASog_I"
      },
      "source": [
        "### 3. Sequential() 모델 생성\n",
        "#### 최적화함수와 손실함수 선택\n",
        "\n",
        "* Build the `tf.keras.Sequential` model by stacking layers. \n",
        "* Choose an optimizer and loss function for training:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDdk4XHheOUc"
      },
      "source": [
        "### 미션: Sequential() 함수의 이해\n",
        "\n",
        "* Sequential() 기법 이해\n",
        "\n",
        "* Flatten() 레이어 이해\n",
        "\n",
        "* Dropout() 레이어 이해\n",
        "\n",
        "* Dense() 레이어 이해\n",
        "\n",
        "* Conv2D() 레이어 적용\n",
        "\n",
        "* MaxPooling2D() 레이어 적용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3IKyzTCDNGo"
      },
      "source": [
        "# Sequential()\n",
        "# Flatten()\n",
        "# Dense()\n",
        "# activation='relu'\n",
        "# Dropout()\n",
        "\n",
        "model = tf.keras.###.###([\n",
        "  tf.keras.layers.###(input_shape=(28, 28)),\n",
        "  tf.keras.layers.###(128, activation='###'),\n",
        "  tf.keras.layers.###(0.2),\n",
        "  tf.keras.layers.Dense(10)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2hiez2eIUz8"
      },
      "source": [
        "### 4. 예측 정확도 지표: 각 데이터에 대한 logits 또는 log-odds 점수 반환\n",
        "#### (아직은 예측의 정확도를 알기 어려움) \n",
        "\n",
        "* For each example \n",
        "* the model returns a vector of \"[logits](https://developers.google.com/machine-learning/glossary#logits)\" or \n",
        "* \"[log-odds](https://developers.google.com/machine-learning/glossary#log-odds)\" scores, one for each class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeOrNdnkEEcR"
      },
      "source": [
        "# model()\n",
        "\n",
        "predictions = ###(x_train[:1]).numpy()\n",
        "predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgjhDQGcIniO"
      },
      "source": [
        "### 5. 예측 정확도: softmax 함수를 이용, 정확한 예측의 확률로 변환\n",
        "\n",
        "* The `tf.nn.softmax` function converts these logits \n",
        "* to \"probabilities\" for each class: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWSRnQ0WI5eq"
      },
      "source": [
        "# softmax()\n",
        "\n",
        "tf.nn.###(predictions).numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "he5u_okAYS4a"
      },
      "source": [
        "#### 참고: `tf.nn.softmax`를 활성화 함수의 마지막 레이어로 추가 가능 (권장 않음)\n",
        "\n",
        "* Note: It is possible to bake this `tf.nn.softmax` in as the activation function for the last layer of the network. \n",
        "\n",
        "* While this can make the model output more directly interpretable, \n",
        "\n",
        "* this approach is discouraged as it's impossible to provide an exact and numerically stable loss calculation for all models \n",
        "* when using a softmax output. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQyugpgRIyrA"
      },
      "source": [
        "### 6. 손실함수 설정\n",
        "\n",
        "\n",
        "* The `losses.SparseCategoricalCrossentropy` loss \n",
        "* takes a vector of logits \n",
        "* and a `True` index and returns a scalar loss for each example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSkzdv8MD0tT"
      },
      "source": [
        "# .losses\n",
        "# SparseCategoricalCrossentropy()\n",
        "# from_logits\n",
        "\n",
        "loss_fn = tf.keras.###.SparseCategoricalCrossentropy(from_logits=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfR4MsSDU880"
      },
      "source": [
        "#### 훈련 전 모델의 손실함수 값의 범위\n",
        "##### 음수가 올바른 분류, 0은 정확\n",
        "\n",
        "* This loss is equal to the negative log probability of the true class:\n",
        "\n",
        "* It is zero if the model is sure of the correct class.\n",
        "\n",
        "* This untrained model gives probabilities close to random (1/10 for each class), \n",
        "* so the initial loss should be close to `-tf.log(1/10) ~= 2.3`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJWqEVrrJ7ZB"
      },
      "source": [
        "# loss_fn()\n",
        "\n",
        "loss_fn(y_train[:1], predictions).numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCCRm0G4VlVJ"
      },
      "source": [
        "### 7. 모델 컴파일\n",
        "\n",
        "* 최적화함수\n",
        "* 손실함수\n",
        "* 지표 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9foNKHzTD2Vo"
      },
      "source": [
        "# compile()\n",
        "# optimizer\n",
        "# loss\n",
        "# metrics\n",
        "\n",
        "model.###(###='adam',\n",
        "              ###=loss_fn,\n",
        "              ###=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ix4mEL65on-w"
      },
      "source": [
        "### 8. 모델 훈련\n",
        "#### 손실함수를 최소화할 수 있는 파라미터 조정\n",
        "\n",
        "* 피처 데이터: x\n",
        "* 타겟 데이터: y\n",
        "* 반복시행 횟수: epochs\n",
        "* The `Model.fit` method \n",
        "* adjusts the model parameters to minimize the loss: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7suUbJXVLqP"
      },
      "source": [
        "# fit()\n",
        "# 피처 훈련데이터\n",
        "# 타겟 훈련데이터\n",
        "# 5회 반복\n",
        "\n",
        "model.###(###, ###, ###=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mDAAPFqVVgn"
      },
      "source": [
        "### 9. 모델의 예측 성능 평가\n",
        "\n",
        "* 피처 데이터: x\n",
        "* 타겟 데이터: y\n",
        "* 결과 표시의 방법: verbose\n",
        "* The `Model.evaluate` method \n",
        "* checks the models performance, usually on a \"[Validation-set](https://developers.google.com/machine-learning/glossary#validation-set)\" or \"[Test-set](https://developers.google.com/machine-learning/glossary#test-set)\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7dTAzgHDUh7"
      },
      "source": [
        "# evaluate()\n",
        "# 피처 검증데이터\n",
        "# 타겟 검증데이터\n",
        "# 결과 표시 방법: 0~2\n",
        "\n",
        "model.###(###, ###, verbose=#)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4JfEh7kvx6m"
      },
      "source": [
        "### 10. 모델 훈련 완료, 활용\n",
        "\n",
        "* The image classifier is now trained to ~98% accuracy on this dataset. \n",
        "* If you want your model to return a probability, \n",
        "* you can wrap the trained model, and attach the softmax to it:\n",
        "* To learn more, read the [TensorFlow tutorials](https://www.tensorflow.org/tutorials/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYb6DrEH0GMv"
      },
      "source": [
        "# Sequential()\n",
        "# Softmax()\n",
        "\n",
        "probability_model = tf.keras.###([\n",
        "  model,\n",
        "  tf.keras.layers.###()\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnqOZtUp1YR_"
      },
      "source": [
        "# 피처 검증데이터 배열 1까지 출력\n",
        "\n",
        "probability_model(x_test[:1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVeMsJNEYnOT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}